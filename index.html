<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Raghavendra Kotikalapudi</title>
    <meta name="description" content="Researcher at Microsoft AI. Previously at Google DeepMind working on Gemini. Creator of keras-vis.">

    <!-- Open Graph / Social -->
    <meta property="og:title" content="Raghavendra Kotikalapudi">
    <meta property="og:description" content="Researcher at Microsoft AI. Previously at Google DeepMind working on Gemini.">
    <meta property="og:type" content="website">

    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
</head>
<body>
    <div class="container">
        <!-- Header / About -->
        <header class="header">
            <div class="header-content">
                <img src="profile.png" alt="Raghavendra Kotikalapudi" class="profile-photo">
                <div class="header-text">
                    <h1>Raghavendra (Ragha) Kotikalapudi</h1>
                    <nav class="social-links">
                        <a href="https://scholar.google.com/citations?user=g2UodAsAAAAJ&hl=en" title="Google Scholar"><i class="fa-brands fa-google-scholar"></i></a>
                        <a href="https://github.com/raghakot" title="GitHub"><i class="fa-brands fa-github"></i></a>
                        <a href="https://www.linkedin.com/in/raghakot/" title="LinkedIn"><i class="fa-brands fa-linkedin"></i></a>
                        <a href="https://x.com/raghakot" title="X"><i class="fa-brands fa-x-twitter"></i></a>
                    </nav>
                    <div class="bio">
                        <p>
                            I am an AI Researcher at <a href="https://microsoft.ai/">Microsoft AI</a> on the <a href="https://microsoft.ai/superintelligence/">MSI team</a> under <a href="https://scholar.google.com/citations?user=L7lMQkQAAAAJ">Karen Simonyan</a>.
                        </p>
                        <p>
                            Previously at <a href="https://deepmind.google/">Google DeepMind</a>, I contributed to <a href="https://deepmind.google/technologies/gemini/">Gemini</a>'s post-training
                            from 1.5 Pro through 3.0 Pro thinking models, including the superhuman coding effort that led to
                            <a href="https://deepmind.google/discover/blog/gemini-achieves-gold-level-performance-at-the-international-collegiate-programming-contest-world-finals/">Gemini winning ICPC Gold</a>.
                            I was also the research lead for instruction tuning and safety on Bard and Gemini 1.5.
                        </p>
                    </div>
                </div>
            </div>
        </header>

        <main>
            <!-- News / Highlights -->
            <section class="section">
                <h2>News</h2>
                <ul class="news-list">
                    <li>
                        <span class="news-date">Jun 2026</span>
                        <span class="news-content">
                            <strong>Gemini STOC Reviewer</strong> — Contributed to the Gemini Deep Think team that provided
                            <a href="https://research.google/blog/gemini-provides-automated-feedback-for-theoretical-computer-scientists-at-stoc-2026/">automated feedback for STOC 2026</a>.
                            Over 80% of submitted papers opted in, with 97% finding the feedback helpful.
                        </span>
                    </li>
                    <li>
                        <span class="news-date">Sep 2025</span>
                        <span class="news-content">
                            <strong>Gemini ICPC Gold</strong> — Key contributor to the Gemini 2.5 Deep Think team that achieved
                            <a href="https://deepmind.google/discover/blog/gemini-achieves-gold-level-performance-at-the-international-collegiate-programming-contest-world-finals/">gold-medal level performance</a>
                            at the ICPC World Finals in Baku. Placed 2nd overall, solving 10/12 problems including Problem C which no human team could solve.
                        </span>
                    </li>
                    <li>
                        <span class="news-date">Oct 2017</span>
                        <span class="news-content">
                            <strong>Facebook Hackathon Winner</strong> — Won the
                            <a href="https://www.geekwire.com/2017/facebook-hackathon-engineers-combine-seattle-data-machine-learning-solve-civic-issues/">Facebook Civic Hackathon</a>
                            with "Find 'n Park", a computer vision model to detect available parking spots in real-time using Seattle's open data.
                        </span>
                    </li>
                    <li>
                        <span class="news-date">Jun 2012</span>
                        <span class="news-content">
                            <strong>NYTimes Op-Ed</strong> — Co-authored
                            <a href="https://www.nytimes.com/2012/06/17/opinion/sunday/how-depressed-people-use-the-internet.html">"How Depressives Surf the Web"</a>
                            in the New York Times Sunday Review, discussing research linking internet usage patterns to depression in college students.
                        </span>
                    </li>
                </ul>
            </section>

            <!-- Selected Publications -->
            <section class="section">
                <h2>Selected Publications</h2>
                <ul class="publications-list">
                    <li class="publication">
                        <a href="https://arxiv.org/abs/2312.11805" class="publication-title">Gemini: A Family of Highly Capable Multimodal Models</a>
                        <span class="publication-authors">G Team, R Anil, S Borgeaud, JB Alayrac, J Yu, R Soricut, J Schalkwyk, ...</span>
                        <span class="publication-venue">arXiv 2023</span>
                        <span class="publication-citations">7,214 citations</span>
                    </li>
                    <li class="publication">
                        <a href="https://arxiv.org/abs/2403.05530" class="publication-title">Gemini 1.5: Unlocking Multimodal Understanding Across Millions of Tokens of Context</a>
                        <span class="publication-authors">G Team, P Georgiev, VI Lei, R Burnell, L Bai, A Gulati, G Tanzer, ...</span>
                        <span class="publication-venue">arXiv 2024</span>
                        <span class="publication-citations">3,394 citations</span>
                    </li>
                    <li class="publication">
                        <a href="https://arxiv.org/abs/2507.06261" class="publication-title">Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities</a>
                        <span class="publication-authors">G Comanici, E Bieber, M Schaekermann, I Pasupat, N Sachdeva, I Dhillon, ...</span>
                        <span class="publication-venue">arXiv 2025</span>
                        <span class="publication-citations">1,504 citations</span>
                    </li>
                    <li class="publication">
                        <a href="https://ieeexplore.ieee.org/document/6387969" class="publication-title">Associating Internet Usage with Depressive Behavior Among College Students</a>
                        <span class="publication-authors">R Katikalapudi, S Chellappan, F Montgomery, D Wunsch, K Lutzen</span>
                        <span class="publication-venue">IEEE Technology and Society Magazine, 2012</span>
                        <span class="publication-citations">125 citations</span>
                    </li>
                    <li class="publication">
                        <a href="https://arxiv.org/abs/2310.16523" class="publication-title">Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting</a>
                        <span class="publication-authors">P Lahoti, N Blumm, X Ma, R Kotikalapudi, S Potluri, Q Tan, H Srinivasan, ...</span>
                        <span class="publication-venue">EMNLP 2023</span>
                    </li>
                </ul>
                <p class="section-more">
                    <a href="https://scholar.google.com/citations?user=g2UodAsAAAAJ&hl=en">Full list on Google Scholar →</a>
                </p>
            </section>

            <!-- Patents -->
            <section class="section">
                <h2>Patents</h2>
                <ul class="publications-list">
                    <li class="publication">
                        <a href="https://patents.google.com/patent/US20240054306A1" class="publication-title">Instruction Following in Large Language Models to Reduce Computational Resource Consumption</a>
                        <span class="publication-authors">R Kotikalapudi, S Mishra, S Potluri, T Bos, Y Du, C Zhu, S Zheng, H Lin, ...</span>
                        <span class="publication-venue">US Patent App. 18/231,586 · 2024</span>
                    </li>
                    <li class="publication">
                        <a href="https://patents.google.com/patent/US20240054307A1" class="publication-title">Reducing Computational Resource Usage via Training and/or Utilizing Large Language Models</a>
                        <span class="publication-authors">R Kotikalapudi, C Zhu, S Zheng, S Potluri, Y Du, HT Cheng, Q Le, EH Chi</span>
                        <span class="publication-venue">US Patent App. 18/231,650 · 2024</span>
                    </li>
                    <li class="publication">
                        <a href="https://patents.google.com/patent/US20250103657A1" class="publication-title">Prompt Complexity for Large Language Models</a>
                        <span class="publication-authors">S Mishra, R Kotikalapudi, O Sarvana, S Potluri, Y Li, T Bos, S Zheng, ...</span>
                        <span class="publication-venue">US Patent App. 18/481,803 · 2025</span>
                    </li>
                    <li class="publication">
                        <a href="https://patents.google.com/patent/US20250094372A1" class="publication-title">Efficient Training and Utilization of Large Language Models</a>
                        <span class="publication-authors">S Mishra, R Kotikalapudi, S Potluri, T Bos, Y Li, H Lin, S Zheng, Y Du, ...</span>
                        <span class="publication-venue">US Patent App. 18/378,434 · 2025</span>
                    </li>
                </ul>
            </section>

            <!-- Open Source -->
            <section class="section">
                <h2>Open Source</h2>
                <ul class="projects-list">
                    <li class="project">
                        <a href="https://github.com/raghakot/keras-vis" class="project-title">keras-vis</a>
                        <span class="project-stars">★ 3,000+</span>
                        <span class="project-desc">Neural network visualization toolkit for Keras. Activation maximization, saliency maps, Grad-CAM, and more.</span>
                    </li>
                    <li class="project">
                        <a href="https://github.com/raghakot/keras-resnet" class="project-title">keras-resnet</a>
                        <span class="project-stars">★ 1,400+</span>
                        <span class="project-desc">Residual Networks implementation using the Keras functional API.</span>
                    </li>
                    <li class="project">
                        <a href="https://github.com/raghakot/keras-text" class="project-title">keras-text</a>
                        <span class="project-stars">★ 422+</span>
                        <span class="project-desc">Text classification library for Keras with support for CNNs, RNNs, and attention models.</span>
                    </li>
                </ul>
                <p class="section-more">
                    <a href="https://github.com/raghakot?tab=repositories">All repositories on GitHub →</a>
                </p>
            </section>
        </main>
    </div>
</body>
</html>
